{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from scipy.stats import pearsonr\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaa\n",
      "['/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_age_test4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_tes10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc12.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr13.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_age1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open13.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr17.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_think1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr14.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_gende1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open12.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_think2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr15.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre16.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre11.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre13.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre14.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre15.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open17.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open15.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open16.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre8.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr12.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre17.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc10.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open19.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_age2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open18.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre6.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr7.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur5.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open14.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui3.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr9.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test2.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test1.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test_deep2_conc4.csv', '/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test_deep2_conc2.csv']\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_age_test4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_tes10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet/results_big5_test7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep/results_big5_test11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc12.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr13.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_age1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open13.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr17.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_think1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr14.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_gende1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open12.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_think2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr15.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre16.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre11.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre13.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre14.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre15.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open17.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open15.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open16.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre8.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr12.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre17.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc10.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open19.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_perc2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_age2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intro5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open18.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_agre6.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr7.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_neur5.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open14.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_intui3.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_conc9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_extr9.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test2.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test1.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test_deep2_conc4.csv\n",
      "/home/mbosnjak/PERO/mpr_convo_carpet_deep2/results_big5_test_deep2_conc2.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "print(\"aaaaaa\")\n",
    "main_path = '/home/mbosnjak/PERO'\n",
    "list_of_resutls = []\n",
    "dirs = [join(main_path,f) for f in listdir(main_path) if f.startswith('mpr')]\n",
    "for path in dirs:\n",
    "    list_of_resutls.extend([join(path,f) for f in listdir(path) if isfile(join(path, f)) and f.startswith('results')])\n",
    "print(list_of_resutls)\n",
    "a = pd.DataFrame()\n",
    "for results_file in list_of_resutls:\n",
    "    results = pd.read_csv(results_file)\n",
    "    print(results_file)\n",
    "    if \"test_f1\" in results.columns:\n",
    "        a = a.append(results[(results['test_f1'].notnull())])\n",
    "    if \"test_mse\" in results.columns:\n",
    "        a = a.append(results[(results['test_mse'].notnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_func', 'alpha', 'batch_size', 'dropout', 'epoch',\n",
       "       'experiments_name', 'fold', 'hash_id', 'hidden_layer_1',\n",
       "       'hidden_layers', 'kernels_count', 'learning_rate', 'models_name',\n",
       "       'pieces_count', 'regularization_type', 'run_identificator',\n",
       "       'sentences_count', 'test_mse', 'test_pearson', 'test_r2_score', 'trait',\n",
       "       'val_mse', 'val_pearson', 'val_r2_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONCIENTIOUSNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1292.694</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.330</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>67.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_tes10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1022.264</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>399.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1092.143</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>90.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.174</td>\n",
       "      <td>980.829</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.005</td>\n",
       "      <td>12</td>\n",
       "      <td>2.500</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>13.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>952.532</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1246.535</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>981.774</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>16.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.099</td>\n",
       "      <td>973.549</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.107</td>\n",
       "      <td>974.715</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>133.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.089</td>\n",
       "      <td>1119.377</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.175</td>\n",
       "      <td>9</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>14.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>955.125</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc11</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>936.846</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.081</td>\n",
       "      <td>955.908</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1208.075</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1252.278</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.060</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>1308.933</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc5</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1001.057</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1265.763</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc7</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1331.828</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.097</td>\n",
       "      <td>932.946</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_conc9</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.112</td>\n",
       "      <td>930.169</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_deep2_conc2</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1022.866</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>43.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_deep2_conc4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1005.164</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>33.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fold test_pearson test_mse learning_rate alpha  \\\n",
       "                       mean         mean     mean          mean  mean   \n",
       "run_identificator                                                       \n",
       "age_test4             0.000        0.040 1292.694         0.001 0.330   \n",
       "big5_tes10            0.000        0.030 1022.264         0.005 0.000   \n",
       "big5_test11           0.000        0.047 1092.143         0.007 0.198   \n",
       "big5_test2            0.000        0.174  980.829         0.152 0.005   \n",
       "big5_test3            0.000        0.011  952.532         0.001 0.000   \n",
       "big5_test4            0.000        0.024 1246.535         0.005 0.005   \n",
       "big5_test5            0.000        0.054  981.774         0.001 0.200   \n",
       "big5_test6            0.500        0.099  973.549         0.001 0.178   \n",
       "big5_test7            0.500        0.107  974.715         0.000 0.178   \n",
       "big5_test_conc1       0.500        0.089 1119.377         0.001 0.175   \n",
       "big5_test_conc10      2.000        0.095  955.125         0.001 0.200   \n",
       "big5_test_conc11      2.000        0.055  936.846         0.001 0.150   \n",
       "big5_test_conc12      0.000        0.081  955.908         0.001 0.150   \n",
       "big5_test_conc2       0.000        0.022 1208.075         0.005 0.010   \n",
       "big5_test_conc3       0.000       -0.080 1252.278         0.010 0.060   \n",
       "big5_test_conc4       2.000        0.027 1308.933         0.010 0.010   \n",
       "big5_test_conc5       2.000        0.092 1001.057         0.001 0.010   \n",
       "big5_test_conc6       2.000        0.057 1265.763         0.010 0.100   \n",
       "big5_test_conc7       2.000        0.070 1331.828         0.010 0.120   \n",
       "big5_test_conc8       2.000        0.097  932.946         0.001 0.120   \n",
       "big5_test_conc9       2.000        0.112  930.169         0.001 0.120   \n",
       "big5_test_deep2_conc2 2.000        0.070 1022.866         0.000 0.200   \n",
       "big5_test_deep2_conc4 2.000        0.076 1005.164         0.000 0.200   \n",
       "\n",
       "                      kernels_count sentences_count pieces_count  \\\n",
       "                               mean            mean         mean   \n",
       "run_identificator                                                  \n",
       "age_test4                         8           4.000          nan   \n",
       "big5_tes10                       12           2.000          nan   \n",
       "big5_test11                      12           3.000          nan   \n",
       "big5_test2                       12           2.500       12.000   \n",
       "big5_test3                        8           4.000       10.000   \n",
       "big5_test4                        8           4.000       20.000   \n",
       "big5_test5                        8           4.000       20.000   \n",
       "big5_test6                        8           2.000          nan   \n",
       "big5_test7                        4           2.000          nan   \n",
       "big5_test_conc1                   9           4.000       20.000   \n",
       "big5_test_conc10                  8           2.000       10.000   \n",
       "big5_test_conc11                  8           2.000        8.000   \n",
       "big5_test_conc12                  8           2.000        8.000   \n",
       "big5_test_conc2                   8           4.000       10.000   \n",
       "big5_test_conc3                   6           4.000        4.000   \n",
       "big5_test_conc4                  12           3.000       12.000   \n",
       "big5_test_conc5                   8           2.000       14.000   \n",
       "big5_test_conc6                   8           2.000        6.000   \n",
       "big5_test_conc7                   8           2.000        6.000   \n",
       "big5_test_conc8                   8           2.000        6.000   \n",
       "big5_test_conc9                   8           2.000       10.000   \n",
       "big5_test_deep2_conc2             8           2.000        8.000   \n",
       "big5_test_deep2_conc4             8           2.000        8.000   \n",
       "\n",
       "                      hidden_layer_1   epoch  \n",
       "                                mean    mean  \n",
       "run_identificator                             \n",
       "age_test4                      2.000  67.000  \n",
       "big5_tes10                     4.000 399.000  \n",
       "big5_test11                    4.000  90.500  \n",
       "big5_test2                    12.000  13.500  \n",
       "big5_test3                    12.000  13.000  \n",
       "big5_test4                    20.000   4.000  \n",
       "big5_test5                    20.000  16.000  \n",
       "big5_test6                    10.000   4.500  \n",
       "big5_test7                     4.000 133.000  \n",
       "big5_test_conc1               23.000  14.000  \n",
       "big5_test_conc10              20.000  12.400  \n",
       "big5_test_conc11              20.000   8.000  \n",
       "big5_test_conc12              20.000  12.000  \n",
       "big5_test_conc2               26.000   4.000  \n",
       "big5_test_conc3                4.000   6.000  \n",
       "big5_test_conc4               12.000   1.000  \n",
       "big5_test_conc5               20.000  12.200  \n",
       "big5_test_conc6                8.000   2.800  \n",
       "big5_test_conc7               20.000   1.800  \n",
       "big5_test_conc8               20.000  12.800  \n",
       "big5_test_conc9               20.000   7.600  \n",
       "big5_test_deep2_conc2            nan  43.800  \n",
       "big5_test_deep2_conc4            nan  33.400  "
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'conscientiousness\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'alpha', 'kernels_count', 'sentences_count', 'experiments_name', 'pieces_count', \"hidden_layer_1\", 'epoch']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>46.386</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.330</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.000</td>\n",
       "      <td>28.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_age1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342</td>\n",
       "      <td>44.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>156.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_age2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371</td>\n",
       "      <td>51.215</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>16.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold test_pearson test_mse learning_rate alpha  \\\n",
       "                  mean         mean     mean          mean  mean   \n",
       "run_identificator                                                  \n",
       "age_test4            0        0.317   46.386         0.001 0.330   \n",
       "big5_test_age1       2        0.342   44.196         0.000 0.190   \n",
       "big5_test_age2       2        0.371   51.215         0.001 0.190   \n",
       "\n",
       "                  kernels_count sentences_count pieces_count hidden_layer_1  \\\n",
       "                           mean            mean         mean           mean   \n",
       "run_identificator                                                             \n",
       "age_test4                     8               4          nan          8.000   \n",
       "big5_test_age1                8               4       12.000         20.000   \n",
       "big5_test_age2                8               4       12.000         20.000   \n",
       "\n",
       "                    epoch  \n",
       "                     mean  \n",
       "run_identificator          \n",
       "age_test4          28.000  \n",
       "big5_test_age1    156.800  \n",
       "big5_test_age2     16.400  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'age\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'alpha', 'kernels_count', 'sentences_count', 'experiments_name', 'pieces_count', \"hidden_layer_1\", 'epoch']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEUTORICISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1156.186</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>95.000</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1143.217</td>\n",
       "      <td>0.007</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>97.000</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1343.896</td>\n",
       "      <td>0.152</td>\n",
       "      <td>12</td>\n",
       "      <td>2.500</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1719.266</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>1406.394</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.172</td>\n",
       "      <td>1266.054</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1231.385</td>\n",
       "      <td>0.026</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1051.837</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1773.375</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur10</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.128</td>\n",
       "      <td>1090.762</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur11</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1031.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>86.600</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>1504.542</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1032.107</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>126.800</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1033.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>136.400</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur5</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1215.590</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>1212.615</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.600</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur7</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1042.189</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>125.000</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>1030.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>118.600</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_neur9</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1036.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>107.800</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fold test_pearson test_mse learning_rate kernels_count  \\\n",
       "                   mean         mean     mean          mean          mean   \n",
       "run_identificator                                                           \n",
       "age_test4         0.000        0.109 1156.186         0.001            12   \n",
       "big5_test11       0.000        0.096 1143.217         0.007            12   \n",
       "big5_test2        0.000        0.066 1343.896         0.152            12   \n",
       "big5_test3        0.000        0.082 1719.266         0.005             8   \n",
       "big5_test4        0.000        0.163 1406.394         0.005             8   \n",
       "big5_test5        0.000        0.172 1266.054         0.001             8   \n",
       "big5_test6        0.500        0.040 1231.385         0.026             8   \n",
       "big5_test7        0.000        0.085 1051.837         0.001             4   \n",
       "big5_test_neur1   0.000        0.111 1773.375         0.010             8   \n",
       "big5_test_neur10  0.500        0.128 1090.762         0.000             8   \n",
       "big5_test_neur11  2.000        0.148 1031.072         0.000             8   \n",
       "big5_test_neur2   0.000        0.086 1504.542         0.005             8   \n",
       "big5_test_neur3   2.000        0.115 1032.107         0.000             8   \n",
       "big5_test_neur4   2.000        0.115 1033.193         0.000             8   \n",
       "big5_test_neur5   2.000        0.143 1215.590         0.001             8   \n",
       "big5_test_neur6   2.000        0.128 1212.615         0.001             8   \n",
       "big5_test_neur7   2.000        0.085 1042.189         0.000             6   \n",
       "big5_test_neur8   2.000        0.146 1030.565         0.000             8   \n",
       "big5_test_neur9   2.000        0.149 1036.409         0.000             8   \n",
       "\n",
       "                  sentences_count pieces_count hidden_layer_1   epoch alpha  \n",
       "                             mean         mean           mean    mean  mean  \n",
       "run_identificator                                                            \n",
       "age_test4                   4.000          nan          4.000  95.000 0.330  \n",
       "big5_test11                 3.000          nan          4.000  97.000 0.198  \n",
       "big5_test2                  2.500       12.000         12.000   6.000 0.005  \n",
       "big5_test3                  4.000       20.000         12.000   6.000 0.000  \n",
       "big5_test4                  4.000       20.000         20.000   3.000 0.125  \n",
       "big5_test5                  4.000       20.000         20.000  14.000 0.200  \n",
       "big5_test6                  2.000          nan         10.000   4.000 0.178  \n",
       "big5_test7                  2.000          nan          4.000   8.000 0.178  \n",
       "big5_test_neur1             2.000       16.000         28.000   7.000 0.198  \n",
       "big5_test_neur10            8.000       20.000         30.000  88.000 0.220  \n",
       "big5_test_neur11            8.000       16.000         30.000  86.600 0.220  \n",
       "big5_test_neur2             4.000        4.000         16.000   7.000 0.079  \n",
       "big5_test_neur3             4.000       12.000         24.000 126.800 0.120  \n",
       "big5_test_neur4             2.000       12.000         18.000 136.400 0.120  \n",
       "big5_test_neur5             4.000       20.000         20.000  15.000 0.120  \n",
       "big5_test_neur6             4.000       16.000         20.000  15.600 0.120  \n",
       "big5_test_neur7             4.000       12.000         20.000 125.000 0.220  \n",
       "big5_test_neur8             6.000       20.000         26.000 118.600 0.220  \n",
       "big5_test_neur9             6.000       20.000         26.000 107.800 0.220  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'neuroticism\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'kernels_count', 'sentences_count', 'pieces_count', \"hidden_layer_1\", 'epoch', 'alpha']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_func</th>\n",
       "      <th>alpha</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>experiments_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>hash_id</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_pearson</th>\n",
       "      <th>val_precision_0</th>\n",
       "      <th>val_precision_1</th>\n",
       "      <th>val_precision_macro</th>\n",
       "      <th>val_r2_score</th>\n",
       "      <th>val_recall_0</th>\n",
       "      <th>val_recall_1</th>\n",
       "      <th>val_recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.150</td>\n",
       "      <td>64</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mbti_final</td>\n",
       "      <td>0</td>\n",
       "      <td>d862944f04937258c1de768777be7761</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.399</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.150</td>\n",
       "      <td>64</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mbti_final</td>\n",
       "      <td>1</td>\n",
       "      <td>0b27c8fbf1e6344844004421c91f978d</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.104</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.150</td>\n",
       "      <td>64</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mbti_final</td>\n",
       "      <td>2</td>\n",
       "      <td>a982ce760c26524df5e755157cdd6db8</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.150</td>\n",
       "      <td>64</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mbti_final</td>\n",
       "      <td>3</td>\n",
       "      <td>dc1ff0990ccf630b58129e102bca62af</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.394</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sig</td>\n",
       "      <td>0.150</td>\n",
       "      <td>64</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>mbti_final</td>\n",
       "      <td>4</td>\n",
       "      <td>acab37ab523dc0572cc3be907241ca3a</td>\n",
       "      <td>16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.400</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  act_func  alpha  batch_size  dropout  epoch experiments_name  fold  \\\n",
       "0      sig  0.150          64      nan  0.000       mbti_final     0   \n",
       "1      sig  0.150          64      nan  0.000       mbti_final     1   \n",
       "2      sig  0.150          64      nan  0.000       mbti_final     2   \n",
       "3      sig  0.150          64      nan  0.000       mbti_final     3   \n",
       "4      sig  0.150          64      nan  0.000       mbti_final     4   \n",
       "\n",
       "                            hash_id  hidden_layer_1 hidden_layers  ...  \\\n",
       "0  d862944f04937258c1de768777be7761          16.000           NaN  ...   \n",
       "1  0b27c8fbf1e6344844004421c91f978d          16.000           NaN  ...   \n",
       "2  a982ce760c26524df5e755157cdd6db8          16.000           NaN  ...   \n",
       "3  dc1ff0990ccf630b58129e102bca62af          16.000           NaN  ...   \n",
       "4  acab37ab523dc0572cc3be907241ca3a          16.000           NaN  ...   \n",
       "\n",
       "   val_f1  val_mse val_pearson  val_precision_0 val_precision_1  \\\n",
       "0   0.444      nan         nan            0.000           0.797   \n",
       "1   0.173      nan         nan            0.209           0.000   \n",
       "2   0.180      nan         nan            0.219           0.000   \n",
       "3   0.441      nan         nan            0.000           0.789   \n",
       "4   0.445      nan         nan            0.000           0.801   \n",
       "\n",
       "  val_precision_macro  val_r2_score  val_recall_0  val_recall_1  \\\n",
       "0               0.399           nan         0.000         1.000   \n",
       "1               0.104           nan         1.000         0.000   \n",
       "2               0.110           nan         1.000         0.000   \n",
       "3               0.394           nan         0.000         1.000   \n",
       "4               0.400           nan         0.000         1.000   \n",
       "\n",
       "   val_recall_macro  \n",
       "0             0.500  \n",
       "1             0.500  \n",
       "2             0.500  \n",
       "3             0.500  \n",
       "4             0.500  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INTROVERTED\n",
    "# a.columns\n",
    "# a[(a['trait'] == '[\\'introverted\\']')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>big5_test_intro1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.800</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>6.800</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intro8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>12.400</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold test_f1 learning_rate kernels_count sentences_count  \\\n",
       "                  mean    mean          mean          mean            mean   \n",
       "run_identificator                                                            \n",
       "big5_test_intro1     2   0.335         0.000            16               2   \n",
       "big5_test_intro3     2   0.346         0.000             8               2   \n",
       "big5_test_intro4     2   0.235         0.000             8               2   \n",
       "big5_test_intro5     2   0.228         0.000             8               2   \n",
       "big5_test_intro6     2   0.525         0.000            12               2   \n",
       "big5_test_intro7     2   0.541         0.000            12               2   \n",
       "big5_test_intro8     2   0.546         0.000            12               2   \n",
       "\n",
       "                  pieces_count hidden_layer_1  epoch alpha  \n",
       "                          mean           mean   mean  mean  \n",
       "run_identificator                                           \n",
       "big5_test_intro1         6.000         16.000  0.000 0.150  \n",
       "big5_test_intro3         6.000          4.000  0.400 0.150  \n",
       "big5_test_intro4         6.000          4.000  0.000 0.150  \n",
       "big5_test_intro5         6.000          4.000  1.200 0.150  \n",
       "big5_test_intro6         4.000          4.000  8.800 0.150  \n",
       "big5_test_intro7         6.000          4.000  6.800 0.150  \n",
       "big5_test_intro8         6.000         10.000 12.400 0.150  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'introverted\\']')].sort_values(by=['fold', 'test_f1'])[[\"trait\", \"fold\", \"test_f1\", \"models_name\", \"run_identificator\", \"learning_rate\", 'kernels_count', 'sentences_count', 'pieces_count', \"hidden_layer_1\", 'epoch', 'alpha']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>big5_test_intui1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.200</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intui2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>4.600</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_intui3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>6.800</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold test_f1 learning_rate kernels_count sentences_count  \\\n",
       "                  mean    mean          mean          mean            mean   \n",
       "run_identificator                                                            \n",
       "big5_test_intui1     2   0.525         0.000            12               2   \n",
       "big5_test_intui2     2   0.528         0.000            12               2   \n",
       "big5_test_intui3     2   0.525         0.000            12               2   \n",
       "\n",
       "                  pieces_count hidden_layer_1 epoch alpha  \n",
       "                          mean           mean  mean  mean  \n",
       "run_identificator                                          \n",
       "big5_test_intui1         6.000         10.000 5.200 0.150  \n",
       "big5_test_intui2         6.000         16.000 4.600 0.150  \n",
       "big5_test_intui3         6.000         18.000 6.800 0.150  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'intuitive\\']')].sort_values(by=['fold', 'test_f1'])[[\"trait\", \"fold\", \"test_f1\", \"models_name\", \"run_identificator\", \"learning_rate\", 'kernels_count', 'sentences_count', 'pieces_count', \"hidden_layer_1\", 'epoch', 'alpha']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>big5_test_think1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>11.800</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_think2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>6.600</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold test_f1 learning_rate kernels_count sentences_count  \\\n",
       "                  mean    mean          mean          mean            mean   \n",
       "run_identificator                                                            \n",
       "big5_test_think1     2   0.630         0.000            12               2   \n",
       "big5_test_think2     2   0.634         0.000            12               6   \n",
       "\n",
       "                  pieces_count hidden_layer_1  epoch alpha  \n",
       "                          mean           mean   mean  mean  \n",
       "run_identificator                                           \n",
       "big5_test_think1         6.000         18.000 11.800 0.150  \n",
       "big5_test_think2         6.000         12.000  6.600 0.150  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'thinking\\']')].sort_values(by=['fold', 'test_f1'])[[\"trait\", \"fold\", \"test_f1\", \"models_name\", \"run_identificator\", \"learning_rate\", 'kernels_count', 'sentences_count', 'pieces_count', \"hidden_layer_1\", 'epoch', 'alpha']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>big5_test_gende1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.400</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fold test_f1 learning_rate kernels_count sentences_count  \\\n",
       "                  mean    mean          mean          mean            mean   \n",
       "run_identificator                                                            \n",
       "big5_test_gende1     2   0.843         0.000            12               2   \n",
       "\n",
       "                  pieces_count hidden_layer_1  epoch alpha  \n",
       "                          mean           mean   mean  mean  \n",
       "run_identificator                                           \n",
       "big5_test_gende1         6.000         10.000 20.400 0.150  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'is_female\\']')].sort_values(by=['fold', 'test_f1'])[[\"trait\", \"fold\", \"test_f1\", \"models_name\", \"run_identificator\", \"learning_rate\", 'kernels_count', 'sentences_count', 'pieces_count', \"hidden_layer_1\", 'epoch', 'alpha']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGREEABLENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>863.334</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.330</td>\n",
       "      <td>12</td>\n",
       "      <td>6.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.000</td>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_tes10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>868.066</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>399.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.136</td>\n",
       "      <td>1015.413</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>957.502</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>78.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.174</td>\n",
       "      <td>934.661</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.099</td>\n",
       "      <td>12</td>\n",
       "      <td>2.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>967.473</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36</td>\n",
       "      <td>2.500</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>102.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1014.651</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>1023.526</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.094</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.068</td>\n",
       "      <td>958.478</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "      <td>35.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.097</td>\n",
       "      <td>954.403</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>190.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>876.175</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.198</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>957.738</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>12.000</td>\n",
       "      <td>129.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>933.889</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.094</td>\n",
       "      <td>14</td>\n",
       "      <td>2.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>22.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.208</td>\n",
       "      <td>920.347</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>67.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre11</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.209</td>\n",
       "      <td>916.439</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>70.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre13</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>911.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>83.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre14</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>914.481</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>81.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre15</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>918.467</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>64.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre16</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.187</td>\n",
       "      <td>928.669</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>113.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre17</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>918.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>89.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>943.220</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1005.932</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>997.398</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.128</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>13.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre5</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1000.213</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.128</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>10.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>947.202</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.128</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>28.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre7</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.133</td>\n",
       "      <td>1023.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.090</td>\n",
       "      <td>16</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1341.572</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.109</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>3.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_agre9</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1004.736</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fold test_pearson test_mse learning_rate alpha  \\\n",
       "                   mean         mean     mean          mean  mean   \n",
       "run_identificator                                                   \n",
       "age_test4         0.000        0.123  863.334         0.001 0.330   \n",
       "big5_tes10        0.000          nan  868.066         0.005 0.198   \n",
       "big5_test1        0.000        0.136 1015.413         0.003 0.000   \n",
       "big5_test11       0.000        0.062  957.502         0.007 0.198   \n",
       "big5_test2        0.000        0.174  934.661         0.150 0.099   \n",
       "big5_test3        0.000        0.232  967.473         0.003 0.000   \n",
       "big5_test4        0.000        0.289 1014.651         0.005 0.125   \n",
       "big5_test5        0.000        0.301 1023.526         0.001 0.094   \n",
       "big5_test6        0.500        0.068  958.478         0.001 0.178   \n",
       "big5_test7        0.500        0.097  954.403         0.000 0.178   \n",
       "big5_test8        0.000          nan  876.175         0.100 0.198   \n",
       "big5_test9        0.000        0.087  957.738         0.005 0.198   \n",
       "big5_test_agre1   0.000        0.167  933.889         0.001 0.094   \n",
       "big5_test_agre10  2.000        0.208  920.347         0.000 0.190   \n",
       "big5_test_agre11  2.000        0.209  916.439         0.000 0.190   \n",
       "big5_test_agre13  2.000        0.210  911.081         0.000 0.190   \n",
       "big5_test_agre14  2.000        0.210  914.481         0.000 0.190   \n",
       "big5_test_agre15  2.000        0.196  918.467         0.000 0.190   \n",
       "big5_test_agre16  2.000        0.187  928.669         0.000 0.190   \n",
       "big5_test_agre17  2.000        0.210  918.354         0.000 0.190   \n",
       "big5_test_agre2   0.000        0.261  943.220         0.001 0.178   \n",
       "big5_test_agre3   2.000        0.167 1005.932         0.001 0.178   \n",
       "big5_test_agre4   2.000        0.186  997.398         0.001 0.128   \n",
       "big5_test_agre5   2.000        0.159 1000.213         0.001 0.128   \n",
       "big5_test_agre6   2.000        0.157  947.202         0.001 0.128   \n",
       "big5_test_agre7   2.000        0.133 1023.199         0.001 0.090   \n",
       "big5_test_agre8   2.000        0.150 1341.572         0.005 0.109   \n",
       "big5_test_agre9   2.000        0.170 1004.736         0.001 0.190   \n",
       "\n",
       "                  kernels_count sentences_count pieces_count hidden_layer_1  \\\n",
       "                           mean            mean         mean           mean   \n",
       "run_identificator                                                             \n",
       "age_test4                    12           6.000          nan          2.000   \n",
       "big5_tes10                   12           2.000          nan          4.000   \n",
       "big5_test1                   14           2.000          nan          4.000   \n",
       "big5_test11                  12           3.000          nan          4.000   \n",
       "big5_test2                   12           2.500        6.000         12.000   \n",
       "big5_test3                   36           2.500       10.000         20.000   \n",
       "big5_test4                    8           4.000       20.000         20.000   \n",
       "big5_test5                    8           4.000       20.000         20.000   \n",
       "big5_test6                    8           2.000          nan         10.000   \n",
       "big5_test7                    4           2.000          nan          4.000   \n",
       "big5_test8                    4           2.000          nan          4.000   \n",
       "big5_test9                   12           2.000          nan         12.000   \n",
       "big5_test_agre1              14           2.000        6.000         18.000   \n",
       "big5_test_agre10              8           4.000       18.000         20.000   \n",
       "big5_test_agre11              8           4.000       16.000         20.000   \n",
       "big5_test_agre13              8           4.000       12.000         20.000   \n",
       "big5_test_agre14              8           4.000       12.000         24.000   \n",
       "big5_test_agre15              8           4.000       10.000         20.000   \n",
       "big5_test_agre16              8           2.000       12.000         20.000   \n",
       "big5_test_agre17              8           4.000       12.000         20.000   \n",
       "big5_test_agre2               8           4.000       14.000         14.000   \n",
       "big5_test_agre3               8           4.000       14.000         14.000   \n",
       "big5_test_agre4               8           4.000       20.000         20.000   \n",
       "big5_test_agre5               8           4.000       10.000         30.000   \n",
       "big5_test_agre6               8           4.000       10.000         12.000   \n",
       "big5_test_agre7              16           4.000       10.000         20.000   \n",
       "big5_test_agre8               8           4.000       20.000         20.000   \n",
       "big5_test_agre9               8           4.000       20.000         20.000   \n",
       "\n",
       "                    epoch  \n",
       "                     mean  \n",
       "run_identificator          \n",
       "age_test4          26.000  \n",
       "big5_tes10        399.000  \n",
       "big5_test1         15.000  \n",
       "big5_test11        78.000  \n",
       "big5_test2          4.000  \n",
       "big5_test3        102.000  \n",
       "big5_test4          1.000  \n",
       "big5_test5          4.000  \n",
       "big5_test6         35.000  \n",
       "big5_test7        190.000  \n",
       "big5_test8         25.000  \n",
       "big5_test9        129.000  \n",
       "big5_test_agre1    22.000  \n",
       "big5_test_agre10   67.200  \n",
       "big5_test_agre11   70.400  \n",
       "big5_test_agre13   83.600  \n",
       "big5_test_agre14   81.200  \n",
       "big5_test_agre15   64.600  \n",
       "big5_test_agre16  113.200  \n",
       "big5_test_agre17   89.400  \n",
       "big5_test_agre2     5.000  \n",
       "big5_test_agre3    13.000  \n",
       "big5_test_agre4    13.200  \n",
       "big5_test_agre5    10.600  \n",
       "big5_test_agre6    28.200  \n",
       "big5_test_agre7     7.000  \n",
       "big5_test_agre8     3.600  \n",
       "big5_test_agre9     7.200  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'agreeableness\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'alpha', 'kernels_count', 'sentences_count', 'experiments_name', 'pieces_count', \"hidden_layer_1\", 'epoch']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRAVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1029.996</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.330</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>58.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.079</td>\n",
       "      <td>936.610</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>79.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1031.874</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.003</td>\n",
       "      <td>12</td>\n",
       "      <td>2.500</td>\n",
       "      <td>10.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>29.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.168</td>\n",
       "      <td>963.049</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>17.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1097.298</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1101.080</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>19.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1044.523</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "      <td>16.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.085</td>\n",
       "      <td>918.857</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>161.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1344.483</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.158</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1200.710</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr11</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.122</td>\n",
       "      <td>1204.504</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1089.209</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr13</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>1120.896</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>18.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr14</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1092.614</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr15</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>1108.284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>12.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr17</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1054.065</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.220</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.187</td>\n",
       "      <td>1248.307</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1159.371</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1096.070</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr5</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>927.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>121.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr7</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.139</td>\n",
       "      <td>967.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>1145.391</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_extr9</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1118.084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.120</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fold test_pearson test_mse learning_rate alpha  \\\n",
       "                   mean         mean     mean          mean  mean   \n",
       "run_identificator                                                   \n",
       "age_test4         0.000        0.051 1029.996         0.001 0.330   \n",
       "big5_test11       0.000        0.079  936.610         0.005 0.198   \n",
       "big5_test2        0.000        0.158 1031.874         0.150 0.003   \n",
       "big5_test3        0.000        0.168  963.049         0.001 0.000   \n",
       "big5_test4        0.000        0.074 1097.298         0.005 0.125   \n",
       "big5_test5        0.000        0.154 1101.080         0.001 0.125   \n",
       "big5_test6        0.500        0.114 1044.523         0.026 0.178   \n",
       "big5_test7        0.500        0.085  918.857         0.001 0.178   \n",
       "big5_test_extr1   0.500        0.129 1344.483         0.007 0.158   \n",
       "big5_test_extr10  2.000        0.158 1200.710         0.003 0.120   \n",
       "big5_test_extr11  2.000        0.122 1204.504         0.003 0.120   \n",
       "big5_test_extr12  2.000        0.162 1089.209         0.001 0.120   \n",
       "big5_test_extr13  2.000        0.138 1120.896         0.001 0.120   \n",
       "big5_test_extr14  2.000        0.153 1092.614         0.001 0.120   \n",
       "big5_test_extr15  2.000        0.164 1108.284         0.001 0.120   \n",
       "big5_test_extr17  2.000        0.157 1054.065         0.001 0.220   \n",
       "big5_test_extr2   0.000        0.187 1248.307         0.001 0.125   \n",
       "big5_test_extr3   2.000        0.107 1159.371         0.005 0.190   \n",
       "big5_test_extr4   2.000        0.162 1096.070         0.001 0.120   \n",
       "big5_test_extr5   2.000        0.135  927.030         0.000 0.120   \n",
       "big5_test_extr7   2.000        0.139  967.411         0.000 0.120   \n",
       "big5_test_extr8   2.000        0.163 1145.391         0.001 0.120   \n",
       "big5_test_extr9   2.000        0.167 1118.084         0.001 0.120   \n",
       "\n",
       "                  kernels_count sentences_count pieces_count hidden_layer_1  \\\n",
       "                           mean            mean         mean           mean   \n",
       "run_identificator                                                             \n",
       "age_test4                     8           6.000          nan          4.000   \n",
       "big5_test11                  12           3.000          nan          4.000   \n",
       "big5_test2                   12           2.500       10.000          8.000   \n",
       "big5_test3                    8           4.000       20.000         12.000   \n",
       "big5_test4                    8           4.000       20.000         20.000   \n",
       "big5_test5                    8           4.000       20.000         20.000   \n",
       "big5_test6                    8           2.000          nan         10.000   \n",
       "big5_test7                    4           2.000          nan          4.000   \n",
       "big5_test_extr1               8           2.000       20.000         30.000   \n",
       "big5_test_extr10              8           2.000       16.000         20.000   \n",
       "big5_test_extr11              8           2.000       18.000         20.000   \n",
       "big5_test_extr12              8           2.000       18.000         20.000   \n",
       "big5_test_extr13              8           2.000       18.000         24.000   \n",
       "big5_test_extr14              8           2.000       18.000         16.000   \n",
       "big5_test_extr15              8           4.000       18.000         20.000   \n",
       "big5_test_extr17              8           4.000       18.000         20.000   \n",
       "big5_test_extr2               8           2.000       22.000         20.000   \n",
       "big5_test_extr3               8           2.000        4.000         12.000   \n",
       "big5_test_extr4               8           2.000       20.000         20.000   \n",
       "big5_test_extr5               8           2.000       20.000         20.000   \n",
       "big5_test_extr7               8           2.000       20.000         20.000   \n",
       "big5_test_extr8               8           2.000       20.000         20.000   \n",
       "big5_test_extr9               8           2.000       18.000         20.000   \n",
       "\n",
       "                    epoch  \n",
       "                     mean  \n",
       "run_identificator          \n",
       "age_test4          58.000  \n",
       "big5_test11        79.000  \n",
       "big5_test2         29.500  \n",
       "big5_test3         17.000  \n",
       "big5_test4          4.000  \n",
       "big5_test5         19.000  \n",
       "big5_test6         16.000  \n",
       "big5_test7        161.500  \n",
       "big5_test_extr1     5.000  \n",
       "big5_test_extr10    5.600  \n",
       "big5_test_extr11    7.000  \n",
       "big5_test_extr12   14.000  \n",
       "big5_test_extr13   18.600  \n",
       "big5_test_extr14   16.800  \n",
       "big5_test_extr15   12.200  \n",
       "big5_test_extr17   15.000  \n",
       "big5_test_extr2    45.000  \n",
       "big5_test_extr3     5.000  \n",
       "big5_test_extr4    20.400  \n",
       "big5_test_extr5   121.400  \n",
       "big5_test_extr7    40.000  \n",
       "big5_test_extr8    15.200  \n",
       "big5_test_extr9    14.000  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'extraversion\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'alpha', 'kernels_count', 'sentences_count', 'experiments_name', 'pieces_count', \"hidden_layer_1\", 'epoch']].groupby(by=['run_identificator']).agg([np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENNEEESSSSSSSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>alpha</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_identificator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>age_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "      <td>1057.997</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.028</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>34.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_tes10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>1053.017</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>399.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.084</td>\n",
       "      <td>934.488</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>887.769</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.198</td>\n",
       "      <td>12</td>\n",
       "      <td>3.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>142.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.126</td>\n",
       "      <td>852.076</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.005</td>\n",
       "      <td>12</td>\n",
       "      <td>2.500</td>\n",
       "      <td>12.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>1231.747</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1253.976</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>816.755</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.125</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.028</td>\n",
       "      <td>966.524</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.178</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>10.000</td>\n",
       "      <td>13.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test7</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.090</td>\n",
       "      <td>835.169</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.178</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>4.000</td>\n",
       "      <td>106.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1122.706</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.174</td>\n",
       "      <td>9</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>784.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.142</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>92.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open11</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>906.210</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.142</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1015.563</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.142</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open13</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>986.169</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.142</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>4.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open14</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1050.942</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.142</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>5.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open15</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1207.576</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.050</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open16</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>915.504</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.050</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>12.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open17</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>788.764</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.050</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>17.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open18</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>778.483</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>130.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open19</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>773.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.150</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>135.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.228</td>\n",
       "      <td>966.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.041</td>\n",
       "      <td>14</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>1321.874</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>4.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>7.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>897.801</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>15.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open5</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>978.302</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open6</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>974.048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>8</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>16.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open7</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>975.565</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>15.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open8</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.159</td>\n",
       "      <td>917.138</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.043</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>11.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>big5_test_open9</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>794.179</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>93.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fold test_pearson test_mse learning_rate alpha  \\\n",
       "                   mean         mean     mean          mean  mean   \n",
       "run_identificator                                                   \n",
       "age_test4         0.000        0.169 1057.997         0.001 0.028   \n",
       "big5_tes10        0.000        0.087 1053.017         0.005 0.000   \n",
       "big5_test1        0.000        0.084  934.488         0.005 0.000   \n",
       "big5_test11       0.000        0.086  887.769         0.007 0.198   \n",
       "big5_test2        0.000        0.126  852.076         0.152 0.005   \n",
       "big5_test3        0.000        0.121 1231.747         0.005 0.000   \n",
       "big5_test4        0.000        0.235 1253.976         0.005 0.125   \n",
       "big5_test5        0.000        0.245  816.755         0.001 0.125   \n",
       "big5_test6        0.500        0.028  966.524         0.026 0.178   \n",
       "big5_test7        0.500        0.090  835.169         0.001 0.178   \n",
       "big5_test_open1   0.500        0.148 1122.706         0.003 0.174   \n",
       "big5_test_open10  2.000        0.115  784.946         0.000 0.142   \n",
       "big5_test_open11  2.000        0.102  906.210         0.001 0.142   \n",
       "big5_test_open12  2.000        0.109 1015.563         0.003 0.142   \n",
       "big5_test_open13  2.000        0.116  986.169         0.003 0.142   \n",
       "big5_test_open14  2.000        0.080 1050.942         0.003 0.142   \n",
       "big5_test_open15  2.000        0.115 1207.576         0.003 0.050   \n",
       "big5_test_open16  2.000        0.113  915.504         0.001 0.050   \n",
       "big5_test_open17  2.000        0.106  788.764         0.001 0.050   \n",
       "big5_test_open18  2.000        0.085  778.483         0.000 0.050   \n",
       "big5_test_open19  2.000        0.088  773.261         0.000 0.150   \n",
       "big5_test_open2   0.000        0.228  966.010         0.001 0.041   \n",
       "big5_test_open3   0.000        0.109 1321.874         0.005 0.125   \n",
       "big5_test_open4   2.000        0.134  897.801         0.001 0.125   \n",
       "big5_test_open5   2.000        0.115  978.302         0.001 0.043   \n",
       "big5_test_open6   2.000        0.095  974.048         0.001 0.043   \n",
       "big5_test_open7   2.000        0.121  975.565         0.001 0.043   \n",
       "big5_test_open8   2.000        0.159  917.138         0.001 0.043   \n",
       "big5_test_open9   2.000        0.107  794.179         0.000 0.043   \n",
       "\n",
       "                  kernels_count sentences_count pieces_count hidden_layer_1  \\\n",
       "                           mean            mean         mean           mean   \n",
       "run_identificator                                                             \n",
       "age_test4                     8           6.000          nan          4.000   \n",
       "big5_tes10                   12           2.000          nan          4.000   \n",
       "big5_test1                   10           2.000          nan            nan   \n",
       "big5_test11                  12           3.000          nan          4.000   \n",
       "big5_test2                   12           2.500       12.000          8.000   \n",
       "big5_test3                    8           4.000       20.000         20.000   \n",
       "big5_test4                    8           4.000       20.000         20.000   \n",
       "big5_test5                    8           4.000       20.000         20.000   \n",
       "big5_test6                    8           2.000          nan         10.000   \n",
       "big5_test7                    4           2.000          nan          4.000   \n",
       "big5_test_open1               9           4.000       20.000         20.000   \n",
       "big5_test_open10             12           4.000       16.000         26.000   \n",
       "big5_test_open11             12           4.000       10.000         26.000   \n",
       "big5_test_open12             12           4.000       14.000         26.000   \n",
       "big5_test_open13              8           4.000       14.000         26.000   \n",
       "big5_test_open14              8           4.000       14.000         26.000   \n",
       "big5_test_open15              8           4.000       16.000         30.000   \n",
       "big5_test_open16              8           4.000       16.000         30.000   \n",
       "big5_test_open17              8           6.000        6.000          4.000   \n",
       "big5_test_open18              8           6.000        6.000          4.000   \n",
       "big5_test_open19              8           6.000        6.000          4.000   \n",
       "big5_test_open2              14           4.000       20.000         20.000   \n",
       "big5_test_open3              10           4.000       12.000         20.000   \n",
       "big5_test_open4              10           4.000       20.000         20.000   \n",
       "big5_test_open5               8           4.000       20.000         20.000   \n",
       "big5_test_open6               8           4.000       16.000         20.000   \n",
       "big5_test_open7              12           4.000       16.000         24.000   \n",
       "big5_test_open8              12           4.000       16.000         26.000   \n",
       "big5_test_open9              12           4.000       16.000         26.000   \n",
       "\n",
       "                    epoch  \n",
       "                     mean  \n",
       "run_identificator          \n",
       "age_test4          34.000  \n",
       "big5_tes10        399.000  \n",
       "big5_test1          0.000  \n",
       "big5_test11       142.000  \n",
       "big5_test2          5.000  \n",
       "big5_test3          5.000  \n",
       "big5_test4          7.000  \n",
       "big5_test5         15.000  \n",
       "big5_test6         13.500  \n",
       "big5_test7        106.000  \n",
       "big5_test_open1    13.000  \n",
       "big5_test_open10   92.600  \n",
       "big5_test_open11   13.000  \n",
       "big5_test_open12    5.000  \n",
       "big5_test_open13    4.600  \n",
       "big5_test_open14    5.200  \n",
       "big5_test_open15    5.000  \n",
       "big5_test_open16   12.200  \n",
       "big5_test_open17   17.200  \n",
       "big5_test_open18  130.400  \n",
       "big5_test_open19  135.600  \n",
       "big5_test_open2    31.000  \n",
       "big5_test_open3     7.000  \n",
       "big5_test_open4    15.200  \n",
       "big5_test_open5    14.200  \n",
       "big5_test_open6    16.800  \n",
       "big5_test_open7    15.800  \n",
       "big5_test_open8    11.000  \n",
       "big5_test_open9    93.600  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(a['trait'] == '[\\'openness\\']')].sort_values(by=['fold', 'test_mse'])[[\"trait\", \"fold\", \"test_pearson\", \"test_mse\", \"models_name\", \"run_identificator\", \"learning_rate\", 'alpha', 'kernels_count', 'sentences_count', 'experiments_name', 'pieces_count', \"hidden_layer_1\", 'epoch']].groupby(by=['run_identificator']).agg([np.mean], group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test5.csv')\n",
    "data = data.append(pd.read_csv('/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test4.csv'))\n",
    "data = data.append(pd.read_csv('/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test3.csv'))\n",
    "data = data.append(pd.read_csv('/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open1.csv'))\n",
    "data = data.append(pd.read_csv('/home/mbosnjak/PERO/mpr_convo_carpet_deep1/results_big5_test_open2.csv'))\n",
    "trait = 'openness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trait</th>\n",
       "      <th>val_pearson</th>\n",
       "      <th>test_pearson</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>models_name</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>kernels_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>hidden_layer_1</th>\n",
       "      <th>run_identificator</th>\n",
       "      <th>epoch</th>\n",
       "      <th>experiments_name</th>\n",
       "      <th>pieces_count</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.282390</td>\n",
       "      <td>0.227551</td>\n",
       "      <td>672.311646</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.255775</td>\n",
       "      <td>0.227554</td>\n",
       "      <td>681.582703</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.04100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.257532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.458313</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.08223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.249591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>687.283508</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>26</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.268649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>688.334656</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>689.227173</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.232301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>690.282104</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>26</td>\n",
       "      <td>0.19356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>691.523132</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.04100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.228526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692.161255</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>['openness']</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693.997559</td>\n",
       "      <td>convo_carpet_deep1</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>big5_test_open2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>big5_as_regression_max_pool_sliced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trait  val_pearson  test_pearson     val_mse         models_name  \\\n",
       "6   ['openness']     0.282390      0.227551  672.311646  convo_carpet_deep1   \n",
       "41  ['openness']     0.255775      0.227554  681.582703  convo_carpet_deep1   \n",
       "25  ['openness']     0.257532           NaN  684.458313  convo_carpet_deep1   \n",
       "9   ['openness']     0.249591           NaN  687.283508  convo_carpet_deep1   \n",
       "12  ['openness']     0.268649           NaN  688.334656  convo_carpet_deep1   \n",
       "45  ['openness']     0.235857           NaN  689.227173  convo_carpet_deep1   \n",
       "5   ['openness']     0.232301           NaN  690.282104  convo_carpet_deep1   \n",
       "20  ['openness']     0.232481           NaN  691.523132  convo_carpet_deep1   \n",
       "15  ['openness']     0.228526           NaN  692.161255  convo_carpet_deep1   \n",
       "39  ['openness']     0.220672           NaN  693.997559  convo_carpet_deep1   \n",
       "\n",
       "    learning_rate  kernels_count  sentences_count  hidden_layer_1  \\\n",
       "6          0.0010             10                4              20   \n",
       "41         0.0005             14                4              20   \n",
       "25         0.0050             14                2              20   \n",
       "9          0.0010             10                4              20   \n",
       "12         0.0050              8                4              20   \n",
       "45         0.0005             16                4              20   \n",
       "5          0.0010              8                4              20   \n",
       "20         0.0010             16                2              20   \n",
       "15         0.0010             14                4              20   \n",
       "39         0.0005             14                4              20   \n",
       "\n",
       "   run_identificator  epoch                    experiments_name  pieces_count  \\\n",
       "6    big5_test_open1   20.0  big5_as_regression_max_pool_sliced            20   \n",
       "41   big5_test_open2   31.0  big5_as_regression_max_pool_sliced            20   \n",
       "25   big5_test_open2    7.0  big5_as_regression_max_pool_sliced            20   \n",
       "9    big5_test_open1   12.0  big5_as_regression_max_pool_sliced            26   \n",
       "12   big5_test_open1    7.0  big5_as_regression_max_pool_sliced            20   \n",
       "45   big5_test_open2   22.0  big5_as_regression_max_pool_sliced            20   \n",
       "5    big5_test_open1   11.0  big5_as_regression_max_pool_sliced            26   \n",
       "20   big5_test_open2   15.0  big5_as_regression_max_pool_sliced            20   \n",
       "15   big5_test_open2   12.0  big5_as_regression_max_pool_sliced            20   \n",
       "39   big5_test_open2   21.0  big5_as_regression_max_pool_sliced            20   \n",
       "\n",
       "      alpha  \n",
       "6   0.12500  \n",
       "41  0.04100  \n",
       "25  0.08223  \n",
       "9   0.12500  \n",
       "12  0.12500  \n",
       "45  0.12500  \n",
       "5   0.19356  \n",
       "20  0.04100  \n",
       "15  0.12500  \n",
       "39  0.12500  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['fold'] == 0) & (data['trait'] == f'[\\'{trait}\\']')].sort_values(by=['fold', 'val_mse'])[[\"trait\", \"val_pearson\", \"test_pearson\", \"val_mse\", \"models_name\", \"learning_rate\", 'kernels_count', 'sentences_count', \"hidden_layer_1\", \"run_identificator\", 'epoch', 'experiments_name', 'pieces_count', 'alpha']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_info_df = pd.read_csv('/home/mbosnjak/Datasets/author_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_df = pd.read_csv('/home/mbosnjak/Datasets/comments_last_100_min_20com_per_auth_w_wc_10_200.csv.folds.csv', usecols =['author', 'fold'])\n",
    "test_data_authors = folds_df[(folds_df['fold'] == 0) & (folds_df['author'])]['author'].tolist()\n",
    "train_data_authors = folds_df[(folds_df['fold'] != 0) & (folds_df['author'])]['author'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.619113573407205\n",
      "Dummy pearson is (nan, nan) for trait agreeableness\n",
      "62.58247903075489\n",
      "Dummy pearson is (nan, nan) for trait openness\n",
      "39.80591497227357\n",
      "Dummy pearson is (nan, nan) for trait conscientiousness\n",
      "36.8491260349586\n",
      "Dummy pearson is (nan, nan) for trait extraversion\n",
      "48.89944649446495\n",
      "Dummy pearson is (nan, nan) for trait neuroticism\n",
      "(nan, nan)\n"
     ]
    }
   ],
   "source": [
    "traits = [\"agreeableness\", \"openness\", \"conscientiousness\", \"extraversion\", \"neuroticism\"]\n",
    "for trait in traits:\n",
    "    test = targets_info_df[targets_info_df['author'].isin(test_data_authors) & targets_info_df[trait].notnull()]\n",
    "    train = targets_info_df[targets_info_df['author'].isin(train_data_authors) & targets_info_df[trait].notnull()]\n",
    "    train_mean = train.agg(np.mean)[trait]\n",
    "    print(train_mean)\n",
    "    predicted = [train_mean] * len(test)\n",
    "    true = list(test[trait].values)\n",
    "\n",
    "    pearson_val = pearsonr(true, predicted)\n",
    "    print(f\"Dummy pearson is {pearson_val} for trait {trait}\")\n",
    "    \n",
    "a = [1.0,1.0]\n",
    "b = [0.4, 0.6]\n",
    "print(pearsonr(a,b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
